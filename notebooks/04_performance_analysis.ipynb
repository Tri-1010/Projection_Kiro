{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Performance Analysis & Optimization\n",
    "\n",
    "Notebook ƒë·ªÉ ƒëo l∆∞·ªùng th·ªùi gian ch·∫°y t·ª´ng step v√† t·ªëi ∆∞u h√≥a performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import wraps\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import (CFG, SEGMENT_COLS, BUCKETS_CANON, BUCKETS_30P, BUCKETS_60P, BUCKETS_90P,\n",
    "                    ABSORBING_BASE, MAX_MOB, DENOM_LEVEL)\n",
    "from data_io import load_parquet, validate_schema\n",
    "from transitions import prepare_transitions, estimate_transition_matrices\n",
    "from forecast import build_initial_vectors, forecast, merge_forecast_to_snapshot\n",
    "from metrics import compute_all_del_metrics\n",
    "from calibration import fit_del_curve_factors, apply_matrix_calibration\n",
    "from export import export_all_del_to_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measurement Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance measurement utilities\n",
    "performance_log = []\n",
    "\n",
    "def time_step(step_name):\n",
    "    \"\"\"Decorator to measure execution time of functions\"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start_time = time.time()\n",
    "            result = func(*args, **kwargs)\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            performance_log.append({\n",
    "                'step': step_name,\n",
    "                'duration': duration,\n",
    "                'timestamp': time.strftime('%H:%M:%S', time.localtime(start_time))\n",
    "            })\n",
    "            \n",
    "            print(f\"‚è±Ô∏è  {step_name}: {duration:.2f}s\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def measure_step(step_name, func, *args, **kwargs):\n",
    "    \"\"\"Measure execution time of a function call\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    performance_log.append({\n",
    "        'step': step_name,\n",
    "        'duration': duration,\n",
    "        'timestamp': time.strftime('%H:%M:%S', time.localtime(start_time))\n",
    "    })\n",
    "    \n",
    "    print(f\"‚è±Ô∏è  {step_name}: {duration:.2f}s\")\n",
    "    return result\n",
    "\n",
    "def print_performance_summary():\n",
    "    \"\"\"Print performance summary\"\"\"\n",
    "    if not performance_log:\n",
    "        print(\"No performance data available\")\n",
    "        return\n",
    "    \n",
    "    df_perf = pd.DataFrame(performance_log)\n",
    "    total_time = df_perf['duration'].sum()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df_perf['percentage'] = (df_perf['duration'] / total_time * 100).round(1)\n",
    "    df_perf['duration_formatted'] = df_perf['duration'].apply(lambda x: f\"{x:.2f}s\")\n",
    "    \n",
    "    display(df_perf[['step', 'duration_formatted', 'percentage', 'timestamp']])\n",
    "    \n",
    "    print(f\"\\nüïê Total execution time: {total_time:.2f}s ({total_time/60:.1f} minutes)\")\n",
    "    \n",
    "    # Find bottlenecks\n",
    "    bottlenecks = df_perf[df_perf['percentage'] > 10].sort_values('duration', ascending=False)\n",
    "    if len(bottlenecks) > 0:\n",
    "        print(\"\\nüêå Performance bottlenecks (>10% of total time):\")\n",
    "        for _, row in bottlenecks.iterrows():\n",
    "            print(f\"  ‚Ä¢ {row['step']}: {row['duration_formatted']} ({row['percentage']}%)\")\n",
    "    \n",
    "    return df_perf\n",
    "\n",
    "# Clear previous logs\n",
    "performance_log.clear()\n",
    "print(\"Performance measurement utilities loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load data\n",
    "df = measure_step(\"1. Load parquet data\", load_parquet, '../Oct25.parquet')\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "# Step 2: Validate schema\n",
    "measure_step(\"2. Validate schema\", validate_schema, df, CFG, SEGMENT_COLS, BUCKETS_CANON)\n",
    "\n",
    "# Step 3: Prepare transitions\n",
    "df_trans = measure_step(\"3. Prepare transitions\", prepare_transitions, \n",
    "                       df, CFG, SEGMENT_COLS, BUCKETS_CANON, ABSORBING_BASE)\n",
    "print(f\"Transitions shape: {df_trans.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Transition Matrix Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Estimate transition matrices (usually the slowest step)\n",
    "segment_levels = [(\"GLOBAL\", []), (\"COARSE\", [SEGMENT_COLS[0]] if SEGMENT_COLS else []), (\"FULL\", SEGMENT_COLS)]\n",
    "prior_strengths = {\"coarse\": 100.0, \"full\": 50.0}\n",
    "\n",
    "transitions_dict, transitions_long_df, meta_df = measure_step(\n",
    "    \"4. Estimate transition matrices\",\n",
    "    estimate_transition_matrices,\n",
    "    df_trans, CFG, BUCKETS_CANON, segment_levels, MAX_MOB, \"ead\", 30, prior_strengths, None\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(transitions_dict)} matrices\")\n",
    "print(f\"Transitions long: {transitions_long_df.shape}\")\n",
    "print(f\"Meta data: {meta_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Build initial vectors\n",
    "df_init, denom_map = measure_step(\n",
    "    \"5. Build initial vectors\",\n",
    "    build_initial_vectors,\n",
    "    df, CFG, BUCKETS_CANON, SEGMENT_COLS, DENOM_LEVEL\n",
    ")\n",
    "print(f\"Initial vectors: {df_init.shape}\")\n",
    "\n",
    "# Step 6: Forecast\n",
    "forecast_df = measure_step(\n",
    "    \"6. Forecast EAD distribution\",\n",
    "    forecast,\n",
    "    df_init, transitions_dict, BUCKETS_CANON, MAX_MOB\n",
    ")\n",
    "print(f\"Forecast: {forecast_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: DEL Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Compute DEL metrics\n",
    "del_results = measure_step(\n",
    "    \"7. Compute all DEL metrics\",\n",
    "    compute_all_del_metrics,\n",
    "    df, forecast_df, CFG, SEGMENT_COLS, MAX_MOB, DENOM_LEVEL,\n",
    "    BUCKETS_30P, BUCKETS_60P, BUCKETS_90P\n",
    ")\n",
    "\n",
    "for k, v in del_results.items():\n",
    "    print(f\"  {k}: {v[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Loan-Level Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Map forecast to loan level\n",
    "df_with_forecast = measure_step(\n",
    "    \"8. Map forecast to loan level\",\n",
    "    merge_forecast_to_snapshot,\n",
    "    df, forecast_df, CFG, SEGMENT_COLS, BUCKETS_CANON,\n",
    "    bad_states_30p=BUCKETS_30P,\n",
    "    bad_states_60p=BUCKETS_60P,\n",
    "    bad_states_90p=BUCKETS_90P\n",
    ")\n",
    "print(f\"Loan-level forecast: {df_with_forecast.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Export to Excel\n",
    "import os\n",
    "os.makedirs('../out', exist_ok=True)\n",
    "\n",
    "measure_step(\n",
    "    \"9. Export to Excel\",\n",
    "    export_all_del_to_excel,\n",
    "    '../out/performance_test.xlsx', transitions_long_df, del_results,\n",
    "    forecast_df=forecast_df, meta_df=meta_df\n",
    ")\n",
    "\n",
    "# Step 10: Export parquet\n",
    "measure_step(\n",
    "    \"10. Export loan-level parquet\",\n",
    "    lambda: df_with_forecast.to_parquet('../out/performance_test_loans.parquet', index=False)\n",
    ")\n",
    "\n",
    "print(\"All exports completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print performance summary\n",
    "df_perf = print_performance_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Bar chart of execution times\n",
    "plt.subplot(2, 2, 1)\n",
    "bars = plt.bar(range(len(df_perf)), df_perf['duration'], color='skyblue', edgecolor='navy')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Duration (seconds)')\n",
    "plt.title('Execution Time by Step')\n",
    "plt.xticks(range(len(df_perf)), [f\"S{i+1}\" for i in range(len(df_perf))], rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "             f'{height:.1f}s', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Pie chart of time distribution\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.pie(df_perf['duration'], labels=[f\"S{i+1}\" for i in range(len(df_perf))], \n",
    "        autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Time Distribution by Step')\n",
    "\n",
    "# Cumulative time\n",
    "plt.subplot(2, 2, 3)\n",
    "cumulative = df_perf['duration'].cumsum()\n",
    "plt.plot(range(len(df_perf)), cumulative, 'o-', color='green', linewidth=2, markersize=6)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Cumulative Time (seconds)')\n",
    "plt.title('Cumulative Execution Time')\n",
    "plt.xticks(range(len(df_perf)), [f\"S{i+1}\" for i in range(len(df_perf))], rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Performance breakdown\n",
    "plt.subplot(2, 2, 4)\n",
    "colors = ['red' if x > 20 else 'orange' if x > 10 else 'green' for x in df_perf['percentage']]\n",
    "bars = plt.bar(range(len(df_perf)), df_perf['percentage'], color=colors, alpha=0.7)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Percentage of Total Time')\n",
    "plt.title('Performance Impact by Step')\n",
    "plt.xticks(range(len(df_perf)), [f\"S{i+1}\" for i in range(len(df_perf))], rotation=45)\n",
    "plt.axhline(y=10, color='orange', linestyle='--', alpha=0.7, label='10% threshold')\n",
    "plt.axhline(y=20, color='red', linestyle='--', alpha=0.7, label='20% threshold')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print step details\n",
    "print(\"\\nStep Details:\")\n",
    "for i, row in df_perf.iterrows():\n",
    "    print(f\"S{i+1}: {row['step']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze bottlenecks and provide optimization recommendations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZATION RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identify major bottlenecks\n",
    "major_bottlenecks = df_perf[df_perf['percentage'] > 20].sort_values('duration', ascending=False)\n",
    "minor_bottlenecks = df_perf[(df_perf['percentage'] > 10) & (df_perf['percentage'] <= 20)].sort_values('duration', ascending=False)\n",
    "\n",
    "if len(major_bottlenecks) > 0:\n",
    "    print(\"\\nüö® MAJOR BOTTLENECKS (>20% of total time):\")\n",
    "    for _, row in major_bottlenecks.iterrows():\n",
    "        step_name = row['step']\n",
    "        print(f\"\\n‚Ä¢ {step_name} ({row['percentage']}% - {row['duration']:.1f}s)\")\n",
    "        \n",
    "        # Specific recommendations based on step\n",
    "        if \"transition matrices\" in step_name.lower():\n",
    "            print(\"  üí° Optimizations:\")\n",
    "            print(\"     - Use vectorized operations (already implemented)\")\n",
    "            print(\"     - Consider reducing MAX_MOB if not all needed\")\n",
    "            print(\"     - Reduce segment hierarchy levels if possible\")\n",
    "            print(\"     - Use multiprocessing for different segments\")\n",
    "            \n",
    "        elif \"del metrics\" in step_name.lower():\n",
    "            print(\"  üí° Optimizations:\")\n",
    "            print(\"     - Compute only needed DEL types (30/60/90)\")\n",
    "            print(\"     - Use chunked processing for large datasets\")\n",
    "            print(\"     - Cache intermediate results\")\n",
    "            \n",
    "        elif \"forecast\" in step_name.lower():\n",
    "            print(\"  üí° Optimizations:\")\n",
    "            print(\"     - Use sparse matrices for large state spaces\")\n",
    "            print(\"     - Vectorize matrix multiplications\")\n",
    "            print(\"     - Parallel processing by cohort-segment\")\n",
    "            \n",
    "        elif \"loan level\" in step_name.lower():\n",
    "            print(\"  üí° Optimizations:\")\n",
    "            print(\"     - Use efficient merge operations\")\n",
    "            print(\"     - Consider sampling for very large datasets\")\n",
    "            print(\"     - Use categorical data types\")\n",
    "            \n",
    "        elif \"export\" in step_name.lower():\n",
    "            print(\"  üí° Optimizations:\")\n",
    "            print(\"     - Use compression for parquet files\")\n",
    "            print(\"     - Write Excel sheets in parallel\")\n",
    "            print(\"     - Consider CSV export for faster I/O\")\n",
    "\n",
    "if len(minor_bottlenecks) > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  MINOR BOTTLENECKS (10-20% of total time):\")\n",
    "    for _, row in minor_bottlenecks.iterrows():\n",
    "        print(f\"  ‚Ä¢ {row['step']}: {row['percentage']}% ({row['duration']:.1f}s)\")\n",
    "\n",
    "# General recommendations\n",
    "print(\"\\nüîß GENERAL OPTIMIZATION STRATEGIES:\")\n",
    "print(\"\\n1. Data Size Optimization:\")\n",
    "print(\"   - Use appropriate data types (int32 vs int64, category vs object)\")\n",
    "print(\"   - Filter data early in the pipeline\")\n",
    "print(\"   - Consider data sampling for development/testing\")\n",
    "\n",
    "print(\"\\n2. Memory Management:\")\n",
    "print(\"   - Use chunked processing for large datasets\")\n",
    "print(\"   - Clear intermediate variables when not needed\")\n",
    "print(\"   - Use memory-efficient data structures\")\n",
    "\n",
    "print(\"\\n3. Parallel Processing:\")\n",
    "print(\"   - Process different segments in parallel\")\n",
    "print(\"   - Use multiprocessing for independent computations\")\n",
    "print(\"   - Consider Dask for very large datasets\")\n",
    "\n",
    "print(\"\\n4. Caching:\")\n",
    "print(\"   - Cache transition matrices if reused\")\n",
    "print(\"   - Save intermediate results to disk\")\n",
    "print(\"   - Use memoization for expensive computations\")\n",
    "\n",
    "# Data size analysis\n",
    "print(\"\\nüìä DATA SIZE ANALYSIS:\")\n",
    "print(f\"   - Original data: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"   - Transitions: {df_trans.shape[0]:,} rows √ó {df_trans.shape[1]} columns\")\n",
    "print(f\"   - Forecast: {forecast_df.shape[0]:,} rows √ó {forecast_df.shape[1]} columns\")\n",
    "print(f\"   - Loan-level: {df_with_forecast.shape[0]:,} rows √ó {df_with_forecast.shape[1]} columns\")\n",
    "print(f\"   - Transition matrices: {len(transitions_dict):,} matrices\")\n",
    "\n",
    "# Memory usage\n",
    "memory_usage = {\n",
    "    'Original data': df.memory_usage(deep=True).sum() / 1024**2,\n",
    "    'Transitions': df_trans.memory_usage(deep=True).sum() / 1024**2,\n",
    "    'Forecast': forecast_df.memory_usage(deep=True).sum() / 1024**2,\n",
    "    'Loan-level': df_with_forecast.memory_usage(deep=True).sum() / 1024**2\n",
    "}\n",
    "\n",
    "print(\"\\nüíæ MEMORY USAGE:\")\n",
    "for name, usage in memory_usage.items():\n",
    "    print(f\"   - {name}: {usage:.1f} MB\")\n",
    "print(f\"   - Total: {sum(memory_usage.values()):.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Optimization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data type optimization\n",
    "print(\"\\nüß™ QUICK OPTIMIZATION TEST: Data Types\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Current data types\n",
    "print(\"Current data types:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  {col}: {df[col].dtype}\")\n",
    "\n",
    "# Optimize data types\n",
    "df_optimized = df.copy()\n",
    "\n",
    "# Convert to more efficient types\n",
    "if df_optimized[CFG['mob']].dtype == 'int64':\n",
    "    df_optimized[CFG['mob']] = df_optimized[CFG['mob']].astype('int8')\n",
    "    \n",
    "if df_optimized[CFG['bucket']].dtype == 'object':\n",
    "    df_optimized[CFG['bucket']] = df_optimized[CFG['bucket']].astype('category')\n",
    "    \n",
    "if 'PRODUCT_TYPE' in df_optimized.columns and df_optimized['PRODUCT_TYPE'].dtype == 'object':\n",
    "    df_optimized['PRODUCT_TYPE'] = df_optimized['PRODUCT_TYPE'].astype('category')\n",
    "\n",
    "# Compare memory usage\n",
    "original_memory = df.memory_usage(deep=True).sum() / 1024**2\n",
    "optimized_memory = df_optimized.memory_usage(deep=True).sum() / 1024**2\n",
    "memory_savings = (original_memory - optimized_memory) / original_memory * 100\n",
    "\n",
    "print(f\"\\nMemory usage comparison:\")\n",
    "print(f\"  Original: {original_memory:.1f} MB\")\n",
    "print(f\"  Optimized: {optimized_memory:.1f} MB\")\n",
    "print(f\"  Savings: {memory_savings:.1f}% ({original_memory - optimized_memory:.1f} MB)\")\n",
    "\n",
    "if memory_savings > 5:\n",
    "    print(\"\\n‚úÖ Significant memory savings! Consider implementing data type optimization.\")\n",
    "else:\n",
    "    print(\"\\nüìù Minor memory savings. Data types are already fairly optimized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Summary & Action Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and action items\n",
    "total_time = df_perf['duration'].sum()\n",
    "slowest_step = df_perf.loc[df_perf['duration'].idxmax()]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE SUMMARY & ACTION ITEMS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìà Overall Performance:\")\n",
    "print(f\"   ‚Ä¢ Total execution time: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "print(f\"   ‚Ä¢ Slowest step: {slowest_step['step']} ({slowest_step['duration']:.1f}s)\")\n",
    "print(f\"   ‚Ä¢ Data processed: {df.shape[0]:,} loans, {len(transitions_dict):,} matrices\")\n",
    "\n",
    "# Performance rating\n",
    "if total_time < 30:\n",
    "    rating = \"üöÄ EXCELLENT\"\n",
    "elif total_time < 60:\n",
    "    rating = \"‚úÖ GOOD\"\n",
    "elif total_time < 120:\n",
    "    rating = \"‚ö†Ô∏è  ACCEPTABLE\"\n",
    "else:\n",
    "    rating = \"üêå NEEDS OPTIMIZATION\"\n",
    "\n",
    "print(f\"   ‚Ä¢ Performance rating: {rating}\")\n",
    "\n",
    "print(f\"\\nüéØ Priority Action Items:\")\n",
    "action_items = []\n",
    "\n",
    "# Generate action items based on bottlenecks\n",
    "for _, row in df_perf.iterrows():\n",
    "    if row['percentage'] > 25:\n",
    "        action_items.append(f\"HIGH: Optimize '{row['step']}' ({row['percentage']:.1f}% of total time)\")\n",
    "    elif row['percentage'] > 15:\n",
    "        action_items.append(f\"MEDIUM: Review '{row['step']}' ({row['percentage']:.1f}% of total time)\")\n",
    "\n",
    "if not action_items:\n",
    "    action_items.append(\"LOW: Performance is well-balanced, consider general optimizations\")\n",
    "\n",
    "for i, item in enumerate(action_items, 1):\n",
    "    print(f\"   {i}. {item}\")\n",
    "\n",
    "print(f\"\\nüí° Quick Wins:\")\n",
    "print(f\"   ‚Ä¢ Use data type optimization (potential {memory_savings:.1f}% memory savings)\")\n",
    "print(f\"   ‚Ä¢ Cache transition matrices if running multiple scenarios\")\n",
    "print(f\"   ‚Ä¢ Consider reducing MAX_MOB if full range not needed\")\n",
    "print(f\"   ‚Ä¢ Use parquet instead of Excel for faster I/O\")\n",
    "\n",
    "print(f\"\\nüìä Export performance data for further analysis:\")\n",
    "df_perf.to_csv('../out/performance_analysis.csv', index=False)\n",
    "print(f\"   ‚úì Saved to: out/performance_analysis.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}